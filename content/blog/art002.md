---
title: "Linear Models"
date: 2019-12-11T09:37:33+01:00
draft: false
markup: "goldmark"
math: true
---

## Linear Regression

### Content

- Introduction - Linear Regression
- Estimation and prediction - Linear Regression
- Varios concepts anround Linear Regression
- Advantages and limitation of Linear Regression
- Case study - bike sharing dataset

## Intruction to Linear Regression

### Linear Regression - An Overview

Supervised algorithm for Regression. A form of a parametric model.\
LR refers to a model which can show relationship between two variables.\
Linear relationsship between tow or more variables.\
Predicts the independet variable (y) based on the dependent variables.\
Explores the relationship between target and input features with a linear equation.\
Applies OLS - Ordinary least square method to estimate the coefficients of the inputs.

### Assumptions of Linear Regression

1. Key assumptions
    - Linear and additive relationship between dependent variable and independet variable(s):\
$$
Y = \alpha + \beta \cdot X + \epsilon
$$
    - No correlation between the error terms - No auto-correlation.
    - The independent variables should not be correlated.
    - The error terms must have constant variance.
    - The error terms should follow normal distribution with a mean of 0 and constant variance.

2. What happens if these assumtions are not stisfied?
    - When the **assumption of linearity** is violated, OLS models will yield biased parameter estimates.
    - Autocorrelation inflates t-statistics by undererstimating the standard errors of the coefficients, thereby resulting in unstable model.
    - Normality of error terms is required for the statistical test to be valid.
    - Multicollinearity inflates the standard errors, making it impossible to determine the relative importance of the predictors.
3. Error versus Residual
    - A statistical error (or disturbance) is the amount by which an observation differs from its expected value.
    - A residual (or fittin deviation), on the other hand, is an observable estimate of the unobservable statistical error.

> An error is the difference beetween the observed value and the actual value (very often unobserved, generated by the DGP) and a rediual term refers to the difference between the observed value and the predicted value (by the selected model).
>     

### Few Proposed Solutions

- Non-linearity - Transformation of variables
- Auto-correlation - Find another suitable model such as Time series model
- Heteroscedasticity (non-sonstant variance) - Weighted List Square
- Multicollinearity - BIF/if standard value is beyond threshold, then you can get rid of the variable
